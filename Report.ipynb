{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Inteligence\n",
    "## Maria InÃªs Pinto - 904644\n",
    "\n",
    "# Introduction\n",
    "\n",
    "This project aims to create a robust handwritten digit recognition system through the use of neural networks. The focal point of our effort is the MNIST database, a rich repository with 60,000 images of handwritten numbers ranging from 0 to 9. Each image is intricately composed of 28x28 pixels, presenting a diverse and challenging dataset. Our strategy involves developing and training a neural network model on this extensive database, culminating in a comprehensive evaluation to assess its effectiveness in recognizing and classifying handwritten digits.\n",
    "It will be possible for the user to test our ANN by uploading 28x28 images with digits or writing using the touchpad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Three essential Python libraries, **NumPy**, **Matplotlib** and **TensorFlow**, are integral to this project for distinct reasons. **NumPy** is indispensable for **performing efficient and high-performance mathematical operations**, providing an array-oriented computing framework. It serves as a fundamental tool for handling the numerical aspects of our neural network, facilitating matrix manipulations, and supporting the underlying computations crucial for training and evaluation.\n",
    "\n",
    "**Matplotlib**, on the other hand, is crucial for **visually representing data through plots and charts**. In the context of this project, Matplotlib will be instrumental in illustrating key metrics, visualizing the training process, and showcasing the performance of our handwritten digit recognition system. Graphical representations generated by Matplotlib will offer insights into the effectiveness and learning dynamics of our neural network.\n",
    "\n",
    "**TensorFlow** provides a **high-level API for building and training neural networks**, efficient computation on CPUs and GPUs, pre-built functions and layers, utility functions for datasets, model saving/loading, a vibrant community, and integration with other ML tools. It simplifies the development process and enables efficient training and deployment of deep learning models, making it a cornerstone for tasks like handwritten digit recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing MNIST Data\n",
    "We download and load MNIST data from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 60000 training image with a size of 28 x 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('x_train: ' + str(x_train.shape))\n",
    "print('x_test: ' + str(x_test.shape))\n",
    "print('y_train: ' + str(y_train.shape))\n",
    "print('y_test: ' + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "This code aims to offer a practical and informative visualization of images belonging to the MNIST dataset. The set contains handwritten numeric representations of digits 0 to 9.\n",
    "\n",
    "The specific image at index 7849 is initially displayed, providing a detailed look at how one of the examples in the dataset appears visually, in this case the number 7.\n",
    "\n",
    "Additionally, the code creates a subplot that displays the first instances of each digit from 0 to 9. Each subplot is accompanied by the label corresponding to the digit, providing a quick and efficient overview of the visual characteristics associated with each number. This is particularly useful for familiarization and visual inspection of the dataset, essential in handwritten digit recognition tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_index = 7849\n",
    "print(y_train[image_index])\n",
    "plt.imshow(x_train[image_index], cmap = 'Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 10, figsize = (20,20))\n",
    "\n",
    "for i in range(0,10):\n",
    "  temp = x_train[y_train == i][0]\n",
    "  ax[i].imshow(temp, cmap='gray')\n",
    "  ax[i].set_title(\"Label: {}\".format(i), fontsize = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "tf.keras.utils.normalize function scales pixel values to a standard range (typically 0 to 1). This practice ensures numerical stability, accelerates convergence during training, and promotes better generalization by making the neural network less sensitive to input variations. Normalization enhances the model's performance and stability, contributing to efficient learning and improved adaptability to new, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.keras.utils.normalize(x_train, axis = 1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation\n",
    "To construct our neural network architecture, we will leverage the **Keras library**, a high-level neural networks API. Keras simplifies the implementation of complex neural network models by providing user-friendly interfaces. Specifically, we will make use of the **Sequential model** and **Dense layers** for defining the architecture of our neural network. This combination of libraries empowers us to seamlessly integrate mathematical operations, visualization capabilities, and a user-friendly neural network framework for an effective and comprehensive approach to handwritten digit recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape = (28, 28)))\n",
    "model.add(tf.keras.layers.Dense(128, activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(128, activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs = 100)\n",
    "\n",
    "model.save('digits.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of always fitting the model, we comment the lines before and simply load the saved model.\n",
    "This metrics tell us how accurate our model is.\n",
    "We wanna have a **low loss** and a **high accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('digits.model')\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print (loss)\n",
    "print (accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Flask App\n",
    "We need to create a flask app to handle user requests from the front end and render html using template engine. Right know we are inside the folder **\"app\"** in **\"main.py\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from flask import Flask, render_template, request, jsonify\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "import base64\n",
    "\n",
    "# App and model initializer\n",
    "app = Flask(__name__)\n",
    "title = 'Hand Digit Recognizer'\n",
    "\n",
    "# Loading prebuilt AI\n",
    "model = keras.models.load_model('app/digits.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have two ways to test our app, we have two html pages. \n",
    "Therefore, the home() function is associated with the root URL and renders the 'home.html' template, while the drawing() function is associated with the \"/drawing\" URL for GET requests and renders the 'drawing.html' template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET method\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('home.html', title=title)\n",
    "\n",
    "@app.route('/drawing', methods=['GET'])\n",
    "def drawing():\n",
    "    return render_template('drawing.html', title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction from file\n",
    "\n",
    "The provided Flask route handles POST requests to the root URL ('/'), expecting an uploaded file named 'file.' Upon receiving a file, the code reads its content and processes it as a grayscale image. The image is resized to 28x28 pixels and formatted for input into a pre-trained neural network model. The model predicts the image's class, and the result is printed. The prediction, along with the application title, is then passed to the 'home.html' template for rendering a response. If successful, the predicted class is displayed; otherwise, any exception is caught and displayed as an error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/', methods=['POST'])\n",
    "def result():\n",
    "    print('Post request recieved')\n",
    "    file_str = request.files['file'].read()\n",
    "    file_np = np.fromstring(file_str, np.uint8)\n",
    "    print(f'File recieved : {file_np.shape}')\n",
    "\n",
    "    file_np = cv2.resize(file_np,(28,28))\n",
    "    file_np = np.expand_dims(file_np, axis=0)\n",
    "\n",
    "    try:\n",
    "        prediction = np.argmax(model.predict(file_np))\n",
    "        print(f\"Prediction : {str(prediction)}\")\n",
    "        return render_template('home.html', title=title, response=str(prediction), success=True)\n",
    "    except Exception as e:\n",
    "        return render_template('home.html', title=title, response=str(e))   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction from drawing\n",
    "After receiving base64 data from front end, we need to convert the image from 3 channel to 1 channel (at line 30) because we train the model on one channel images. The image we received from front end has 3 channel (RBG) with the shape (280, 280, 3) and we convert to (280, 280).\n",
    "\n",
    "We need to resize the image to 28 x 28 (at line 33). We need resize the image because our original size was 280 x 280. You can check on canvas tag with width and height of 280 (at line 43). Remember our model was trained using 28 x 28 image, so if we want to predict any images, we need to resize into 28 x 28. Also expand the array dimension from (28, 28) to (1, 28, 28) because the number 1 means we have 1 images with the size 28 x 28.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/canvas', methods=['POST'])\n",
    "def canvas():\n",
    "    canvasdata = request.form['canvasimg']\n",
    "    encoded_data = request.form['canvasimg'].split(',')[1]\n",
    "\n",
    "    # Decode base64\n",
    "    nparr = np.fromstring(base64.b64decode(encoded_data), np.uint8)\n",
    "    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "\n",
    "    # Convert 3 channel to 1 channel\n",
    "    gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imwrite('280x280.jpg', gray_image)\n",
    "\n",
    "    # Resize to (28, 28)\n",
    "    gray_image = cv2.resize(gray_image, (28, 28), interpolation=cv2.INTER_LINEAR)\n",
    "    cv2.imwrite('28x28.jpg', gray_image)\n",
    "\n",
    "    # Expand to (1, 28, 28)\n",
    "    img = np.expand_dims(gray_image, axis=0)\n",
    "\n",
    "    try:\n",
    "        prediction = np.argmax(model.predict(img))\n",
    "        print(f\"Prediction Result : {str(prediction)}\")\n",
    "        return render_template('drawing.html', title=title, response=str(prediction), canvasdata=canvasdata, success=True)\n",
    "    except Exception as e:\n",
    "        return render_template('drawing.html', title=title, response=str(e), canvasdata=canvasdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Upload File App\n",
    "Right now, we are inside the foler **\"templates\"** in **\"home.html\"**\n",
    "On this HTML page, the user can upload images (28x28) to test the program and receive the result on the screen. Furthermore, it is through this that, by clicking on the \"Go to Drawing Page\" button, you can test the app by drawing, using the touchpad, the digits to be tested.\n",
    "In the root, there is a folder **\"digits\"** that has examples to test here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Home Html](htmlPages/HomeHTML.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Drawing App\n",
    "Right now, we are inside the foler **\"templates\"** in **\"drawing.html\"**. We use HTML5 canvas to create a simple working drawing app which can be used to write digits using mouse. Then we can send into our server into base64 image data. As on the first page, here the user, after drawing the digit to be tested, receives the result of the analysis on the screen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Drawing Html](htmlPages/DrawingHTML.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment\n",
    "To test our app we need to run the file \"wsgi.py\" and open the server show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.main import app\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shoul see something like this\n",
    "**Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conlusion\n",
    "In conclusion, this study delved into the application of an Artificial Neural Network (ANN) for the recognition of handwritten digits, leveraging the MNIST dataset. Throughout the project, we explored fundamental concepts of machine learning and neural networks, emphasizing the chosen architecture tailored to the task at hand.\n",
    "\n",
    "The implementation and training of the ANN unveiled the model's ability to generalize complex patterns present in various samples of handwritten digits. The normalization of input data and the selected architecture proved to be crucial elements for the effective performance of the model.\n",
    "\n",
    "However, we can also conclude that the accuracy of our app can be improved since, especially when uploading files, it fails several times. There are several reasons why this happens, which includes **Diversity in Training Data:** If the training dataset is not sufficiently representative in terms of diverse writing styles, sizes, and inclinations, the ANN may struggle to generalize to previously unseen cases.\n",
    "**Overfitting:** Overfitting occurs when the ANN overly adjusts to specific training data and fails to generalize well to new data. This can happen if the model is too complex relative to the complexity of the data or if there is no validation data to monitor performance during training. We therefore conclude that it is a good ANN for recognizing handwritten digits but could be improved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
